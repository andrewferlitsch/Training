{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t0So4QvATZMA"
   },
   "source": [
    "# **iMaterialist Challenge (Furniture) at FGVC5**\n",
    "## **TFNW Kaggle Team**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy for the high performance in-memory matrix/array storage and operations.\n",
    "import numpy as np\n",
    "\n",
    "# Import h5py for the HD5 filesystem high performance file storage of big data.\n",
    "import h5py\n",
    "\n",
    "# Import time to record timing\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the Dataset Batches\n",
    "\n",
    "We are ready to read in the dataset and feed it to our model. We have stored the dataset as a series of batch files, so we will want to read one batch file at a time and feed it into the model.\n",
    "\n",
    "### Feeder\n",
    "\n",
    "The function feeder() performs the feed task for training our model. We use a generator. From wikipedia:\n",
    "\n",
    ">*A generator is a special routine that can be used to control the iteration behaviour of a loop. A generator is very similar to a function that returns an array, in that a generator has parameters, can be called, and generates a sequence of values.  However, instead of building an array containing all the values and returning them all at once, a generator yields the values one at a time, which requires less memory and allows the caller to get started processing the first few values immediately. In short, a generator looks like a function but behaves like an iterator.*\n",
    "\n",
    "The feeder() function takes a list of the HD5 stored batch files. Each time the feeder() function is called, it will read in the next batch file, extract the images and corresponding labels, which are returned as the next batch data (X, Y).\n",
    "\n",
    "Let's take a closer look. The 'while True' may at first appear that the function has an infinite loop and will never return. That's not correct. The key to understanding this is the yield statement. The yield acts similar to a return statement. From Wikipedia:\n",
    "\n",
    ">*The yield statement is used to define generators, replacing the return of a function to provide a result to its caller without destroying local variables. Unlike a function, where on each call it starts with new set of variables, a generator will resume the execution where it was left off.*\n",
    "\n",
    "### Feeding Epochs\n",
    "\n",
    "The 'While True' loop gives the feeder() function the ability to continously cycle through all the batch files. For example, if we have 100 batch files and 2 epochs, the first 100 calls to the feeder will sequentially feed the 100 batch files (see below). The 101st call will cycle back to the while loop and start over again; hence starting the 2nd epoch.\n",
    "\n",
    "### Feeding Batches within an Epoch\n",
    "\n",
    "The 'for batch_file in files:' loop is where the batch files are feed one at a time. This loop on each iteration will select the next batch file in the list files.\n",
    "\n",
    "### Feeding a Batch\n",
    "\n",
    "The 'with h5py.File(batch_file, 'r') as hf:' statement opens the current batch file and reads in the images and corresponding labels. The file is an HD5 encoding. The images are stored in the group section 'images' and the labels in the group section 'labels'. The HD5 encoding allows random access into the file using indexes. \n",
    "\n",
    "To access the 'images' section, we use the associative array access syntax: hf['images']. Likewise, the same for 'labels' section. Within the sections, we copy the entire list of images, and labels using the list copy syntax [:]. For the image data, we normalize the pixel values by converting them from a 0 .. 255 integer range to 0 .. 1 floating point range.\n",
    "\n",
    "Finally, we get to the yield keyword. At this point the feeder() will return the data read into the variables X and Y, and importantly remember where the function left off. The next time the feeder() function is called, it will pick up where it left off and continue to it reaches the yield statement.\n",
    "\n",
    "### Note on Normalization\n",
    "\n",
    "One could ask why we did not store the images in the batch files already normalized. We could have and improve performance in reading in the batch files. \n",
    "\n",
    "But it is a trade off for speed vs. disk space. The 0 .. 255 range can be represented as a 8bit integer value, requiring only one byte per pixel in the stored file. If we pre-convert to 0..1, we have a floating point number. At a minimum, we would need to store this value as a 16bit floating point value, requiring two bytes per pixel, doubling the size of the stored file. The 16bit resolution is low precision, so if we have many layers in the neural network, we could face a vanishing gradient problem. In that case, we would need to store as 32bit floating point value, which would require four bytes per pixel, quadrupling the size of the stored file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feeder(files):\n",
    "    \"\"\" A generator for feeding batches of images to a neural network \n",
    "    files = batches of images/labels as HD5 files\n",
    "    \"\"\"\n",
    "    # We use an infinite loop here so that the generator can be called for an unlimited number of epochs\n",
    "    while True:\n",
    "        # Read each batch file one at a time in sequential order\n",
    "        for batch_file in files:\n",
    "            # Read the batch to disk from the HD5 file\n",
    "            with h5py.File(batch_file, 'r') as hf:\n",
    "                # Read in the images\n",
    "                # Normalize the pixel data (convert 0..255 to 0..1)\n",
    "                X = hf['images'][:] / 255\n",
    "                # Read in the corresponding labels\n",
    "                Y = hf['labels'][:]\n",
    "                yield X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Profiling\n",
    "\n",
    "When finding the optimal balance between memory (space) and speed (performance), it's generally a good idea to do some memory profiling. We install/import the pympler module for memory profiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pympler in c:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\n"
     ]
    }
   ],
   "source": [
    "# Install pympler, used for memory monitoring\n",
    "!pip install pympler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Feeder\n",
    "\n",
    "We are ready now to run the feeder. I have constructed the code below for feeding the training data in batches to a neural network.\n",
    "\n",
    "### Accessing the Batch Files\n",
    "\n",
    "We start by getting a list of all the batch files we have stored in our training subdirectory (contents/train). We then calculate the number of batch files by taking the length of this list.\n",
    "\n",
    "### Running an Epoch\n",
    "\n",
    "Next, we set the number of epochs (n_epochs) and loop through our epoch range. In each loop iteration, we will feed the entire training data in batches. We do this by keeping a count of the number of batches we have ran. The entire epoch is complete when the count equals the total number of batches (i.e., the number of batch files).\n",
    "\n",
    "### Running a Batch\n",
    "\n",
    "Within the epoch loop, we call the iterator on the feeder() function. Each time we call the feeder(), the function will return the images (X) and corresponding labels (Y) from the next batch file.\n",
    "\n",
    "### Garbage Collection\n",
    "\n",
    "After each batch is processed (feed into model), and the X and Y data is no longer referenced, Python does not immediately free the memory. Instead, the Python run-time environment does periodic garbage collection (freeing memory), in the background.\n",
    "\n",
    "The space for X and Y continue to accumulate on the heap until the Python run-time environment implicitly does the garbage collection (i.e. freeing the memory).\n",
    "\n",
    "If the processing of the data is running much faster than the garbage collection cycle, we could have memory space problems. We are solving this by explicitly calling the garbage collection process after eacy batch is processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH #: 0\n",
      "198 (198, 300, 300, 3)\n",
      "198 (198,)\n",
      "                            types |   # objects |   total size\n",
      "================================= | =========== | ============\n",
      "            <class 'numpy.ndarray |           0 |     12.36 MB\n",
      "                     <class 'cell |           4 |    192     B\n",
      "                     <class 'code |           1 |    144     B\n",
      "          function (null_wrapper) |           1 |    136     B\n",
      "            function (store_info) |           1 |    136     B\n",
      "                <class 'generator |           1 |     88     B\n",
      "          <class 'h5py.h5f.FileID |           1 |     88     B\n",
      "                  <class 'weakref |           1 |     80     B\n",
      "        <class 'functools.partial |           1 |     80     B\n",
      "                   <class 'method |           1 |     64     B\n",
      "  <class 'tornado.ioloop._Timeout |           1 |     64     B\n",
      "      <class 'h5py._hl.files.File |           1 |     56     B\n",
      "                    <class 'float |           2 |     48     B\n",
      "                      <class 'int |           1 |     32     B\n",
      "       <class 'h5py.h5l.LinkProxy |           1 |     24     B\n",
      "BATCH #: 1\n",
      "192 (192, 300, 300, 3)\n",
      "192 (192,)\n",
      "                  types |   # objects |        total size\n",
      "======================= | =========== | =================\n",
      "            <class 'str |           4 |         354     B\n",
      "           <class 'list |           4 |         352     B\n",
      "  <class 'numpy.ndarray |           0 |   -12960024     B\n",
      "BATCH #: 2\n",
      "192 (192, 300, 300, 3)\n",
      "192 (192,)\n",
      "        types |   # objects |   total size\n",
      "============= | =========== | ============\n",
      "  <class 'str |           0 |     54     B\n",
      "BATCH #: 3\n",
      "184 (184, 300, 300, 3)\n",
      "184 (184,)\n",
      "                  types |   # objects |        total size\n",
      "======================= | =========== | =================\n",
      "            <class 'str |           0 |          54     B\n",
      "  <class 'numpy.ndarray |           0 |   -17280032     B\n",
      "BATCH #: 4\n",
      "192 (192, 300, 300, 3)\n",
      "192 (192,)\n",
      "                      types |   # objects |   total size\n",
      "=========================== | =========== | ============\n",
      "      <class 'numpy.ndarray |           0 |     16.48 MB\n",
      "               <class 'dict |           1 |    288     B\n",
      "              <class 'tuple |           3 |    184     B\n",
      "               <class 'cell |           3 |    144     B\n",
      "        function (<lambda>) |           1 |    136     B\n",
      "    function (null_wrapper) |           1 |    136     B\n",
      "  <class 'functools.partial |           1 |     80     B\n",
      "               <class 'list |           1 |     72     B\n",
      "                <class 'str |           0 |     54     B\n",
      "BATCH #: 5\n",
      "190 (190, 300, 300, 3)\n",
      "190 (190,)\n",
      "                      types |   # objects |       total size\n",
      "=========================== | =========== | ================\n",
      "                <class 'str |           0 |         54     B\n",
      "                <class 'int |           1 |         28     B\n",
      "               <class 'list |          -1 |        -72     B\n",
      "  <class 'functools.partial |          -1 |        -80     B\n",
      "        function (<lambda>) |          -1 |       -136     B\n",
      "    function (null_wrapper) |          -1 |       -136     B\n",
      "               <class 'cell |          -3 |       -144     B\n",
      "              <class 'tuple |          -3 |       -184     B\n",
      "               <class 'dict |          -1 |       -288     B\n",
      "      <class 'numpy.ndarray |           0 |   -4320008     B\n",
      "BATCH #: 6\n",
      "190 (190, 300, 300, 3)\n",
      "190 (190,)\n",
      "                      types |   # objects |   total size\n",
      "=========================== | =========== | ============\n",
      "               <class 'dict |           1 |    288     B\n",
      "              <class 'tuple |           3 |    184     B\n",
      "               <class 'cell |           3 |    144     B\n",
      "        function (<lambda>) |           1 |    136     B\n",
      "    function (null_wrapper) |           1 |    136     B\n",
      "  <class 'functools.partial |           1 |     80     B\n",
      "               <class 'list |           1 |     72     B\n",
      "                <class 'str |           0 |     54     B\n",
      "                <class 'int |          -1 |    -28     B\n",
      "BATCH #: 7\n",
      "190 (190, 300, 300, 3)\n",
      "190 (190,)\n",
      "                      types |   # objects |   total size\n",
      "=========================== | =========== | ============\n",
      "                <class 'str |           0 |     54     B\n",
      "                <class 'int |           1 |     28     B\n",
      "               <class 'list |          -1 |    -72     B\n",
      "  <class 'functools.partial |          -1 |    -80     B\n",
      "        function (<lambda>) |          -1 |   -136     B\n",
      "    function (null_wrapper) |          -1 |   -136     B\n",
      "               <class 'cell |          -3 |   -144     B\n",
      "              <class 'tuple |          -3 |   -184     B\n",
      "               <class 'dict |          -1 |   -288     B\n",
      "BATCH #: 8\n",
      "189 (189, 300, 300, 3)\n",
      "189 (189,)\n",
      "                  types |   # objects |       total size\n",
      "======================= | =========== | ================\n",
      "            <class 'str |           0 |         54     B\n",
      "            <class 'int |          -1 |        -28     B\n",
      "  <class 'numpy.ndarray |           0 |   -2160004     B\n",
      "BATCH #: 9\n",
      "190 (190, 300, 300, 3)\n",
      "190 (190,)\n",
      "                  types |   # objects |   total size\n",
      "======================= | =========== | ============\n",
      "  <class 'numpy.ndarray |           0 |      2.06 MB\n",
      "            <class 'str |           0 |     54     B\n",
      "BATCH #: 10\n",
      "193 (193, 300, 300, 3)\n",
      "193 (193,)\n",
      "                  types |   # objects |   total size\n",
      "======================= | =========== | ============\n",
      "  <class 'numpy.ndarray |           0 |      6.18 MB\n",
      "            <class 'str |           0 |     55     B\n",
      "BATCH #: 11\n",
      "196 (196, 300, 300, 3)\n",
      "196 (196,)\n",
      "                  types |   # objects |   total size\n",
      "======================= | =========== | ============\n",
      "  <class 'numpy.ndarray |           0 |      6.18 MB\n",
      "            <class 'str |           0 |     54     B\n",
      "BATCH #: 12\n",
      "195 (195, 300, 300, 3)\n",
      "195 (195,)\n",
      "                  types |   # objects |       total size\n",
      "======================= | =========== | ================\n",
      "            <class 'str |           0 |         52     B\n",
      "  <class 'numpy.ndarray |           0 |   -2160004     B\n",
      "BATCH #: 13\n",
      "194 (194, 300, 300, 3)\n",
      "194 (194,)\n",
      "                      types |   # objects |       total size\n",
      "=========================== | =========== | ================\n",
      "               <class 'dict |           1 |        288     B\n",
      "              <class 'tuple |           3 |        184     B\n",
      "               <class 'cell |           3 |        144     B\n",
      "        function (<lambda>) |           1 |        136     B\n",
      "    function (null_wrapper) |           1 |        136     B\n",
      "  <class 'functools.partial |           1 |         80     B\n",
      "               <class 'list |           1 |         72     B\n",
      "                <class 'str |           0 |         52     B\n",
      "      <class 'numpy.ndarray |           0 |   -2160004     B\n",
      "BATCH #: 14\n",
      "196 (196, 300, 300, 3)\n",
      "196 (196,)\n",
      "                      types |   # objects |   total size\n",
      "=========================== | =========== | ============\n",
      "      <class 'numpy.ndarray |           0 |      4.12 MB\n",
      "                <class 'str |           0 |     52     B\n",
      "                <class 'int |           1 |     28     B\n",
      "               <class 'list |          -1 |    -72     B\n",
      "  <class 'functools.partial |          -1 |    -80     B\n",
      "        function (<lambda>) |          -1 |   -136     B\n",
      "    function (null_wrapper) |          -1 |   -136     B\n",
      "               <class 'cell |          -3 |   -144     B\n",
      "              <class 'tuple |          -3 |   -184     B\n",
      "               <class 'dict |          -1 |   -288     B\n",
      "BATCH #: 15\n",
      "191 (191, 300, 300, 3)\n",
      "191 (191,)\n",
      "                  types |   # objects |        total size\n",
      "======================= | =========== | =================\n",
      "            <class 'str |           0 |          52     B\n",
      "            <class 'int |          -1 |         -28     B\n",
      "  <class 'numpy.ndarray |           0 |   -10800020     B\n",
      "BATCH #: 16\n",
      "189 (189, 300, 300, 3)\n",
      "189 (189,)\n",
      "                  types |   # objects |       total size\n",
      "======================= | =========== | ================\n",
      "            <class 'str |           0 |         52     B\n",
      "  <class 'numpy.ndarray |           0 |   -4320008     B\n",
      "BATCH #: 17\n",
      "192 (192, 300, 300, 3)\n",
      "192 (192,)\n",
      "                            types |   # objects |   total size\n",
      "================================= | =========== | ============\n",
      "            <class 'numpy.ndarray |           0 |      6.18 MB\n",
      "              function (<lambda>) |          11 |      1.46 KB\n",
      "                     <class 'cell |          21 |   1008     B\n",
      "                    <class 'tuple |          14 |    872     B\n",
      "                      <class 'str |           3 |    305     B\n",
      "                     <class 'code |           2 |    288     B\n",
      "   function (_schedule_in_thread) |           1 |    136     B\n",
      "                    <class 'float |          -2 |    -48     B\n",
      "                   <class 'method |          -1 |    -64     B\n",
      "  <class 'tornado.ioloop._Timeout |          -1 |    -64     B\n",
      "                     <class 'list |          -1 |    -72     B\n",
      "        <class 'functools.partial |          -1 |    -80     B\n",
      "          function (null_wrapper) |          -1 |   -136     B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH #: 18\n",
      "188 (188, 300, 300, 3)\n",
      "188 (188,)\n",
      "                            types |   # objects |       total size\n",
      "================================= | =========== | ================\n",
      "          function (null_wrapper) |           1 |        136     B\n",
      "        <class 'functools.partial |           1 |         80     B\n",
      "                     <class 'list |           1 |         72     B\n",
      "                   <class 'method |           1 |         64     B\n",
      "  <class 'tornado.ioloop._Timeout |           1 |         64     B\n",
      "                    <class 'float |           2 |         48     B\n",
      "                      <class 'int |          -1 |        -28     B\n",
      "   function (_schedule_in_thread) |          -1 |       -136     B\n",
      "                      <class 'str |          -3 |       -202     B\n",
      "                     <class 'code |          -2 |       -288     B\n",
      "                    <class 'tuple |         -14 |       -872     B\n",
      "                     <class 'cell |         -21 |      -1008     B\n",
      "              function (<lambda>) |         -11 |      -1496     B\n",
      "            <class 'numpy.ndarray |           0 |   -8640016     B\n",
      "BATCH #: 19\n",
      "185 (185, 300, 300, 3)\n",
      "185 (185,)\n",
      "                      types |   # objects |       total size\n",
      "=========================== | =========== | ================\n",
      "               <class 'dict |           1 |        288     B\n",
      "               <class 'cell |           3 |        144     B\n",
      "        function (<lambda>) |           1 |        136     B\n",
      "    function (null_wrapper) |           1 |        136     B\n",
      "              <class 'tuple |           2 |        120     B\n",
      "  <class 'functools.partial |           1 |         80     B\n",
      "               <class 'list |           1 |         72     B\n",
      "                <class 'str |           0 |         53     B\n",
      "                <class 'int |           1 |         28     B\n",
      "      <class 'numpy.ndarray |           0 |   -6480012     B\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Import the garbage (memory management) module\n",
    "import gc\n",
    "\n",
    "# Import pympler.tracker for memory monitoring\n",
    "from pympler import tracker\n",
    "# Create object to monitor the heap\n",
    "tr = tracker.SummaryTracker()\n",
    "\n",
    "# Directory where the training batches are stored\n",
    "batches = \"contents/train/\"\n",
    "\n",
    "# Get a list of all the training\\ batch files\n",
    "batchlist = []\n",
    "for batch in os.listdir(batches):\n",
    "    batchlist.append(os.path.join(batches, batch))\n",
    "    \n",
    "# Number of batches\n",
    "nbatches = len(batchlist)\n",
    "\n",
    "# Number of epochs\n",
    "n_epochs = 1\n",
    "    \n",
    "# Loop through each epoch, each time feeding the entire training set.\n",
    "for epoch in range(n_epochs):\n",
    "    # Iteratively call the feeder() function\n",
    "    nbatch = 0\n",
    "    for X, Y in feeder(batchlist):\n",
    "        # Printing some information so you can see that the next batch file was feed\n",
    "        print(\"BATCH #:\", nbatch)\n",
    "        print(len(X), X.shape)\n",
    "        print(len(Y), Y.shape)\n",
    "        tr.print_diff()\n",
    "        \n",
    "        # HERE is where you feed the training batch data to the neural network\n",
    "        \n",
    "        # This line will force garbage collection of unused memory.\n",
    "        # If the processing of the data is running much faster than the garbage collection cycle,\n",
    "        # we could have memory space problems. We are solving this by explicitly calling the garbage\n",
    "        # collection process after eacy batch is processed.\n",
    "        gc.collect()\n",
    "        \n",
    "        # Run a single epoch\n",
    "        nbatch += 1\n",
    "        if nbatch == nbatches:\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "iMaterialist-download-dataset.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
