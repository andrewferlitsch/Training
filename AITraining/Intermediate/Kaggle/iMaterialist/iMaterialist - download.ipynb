{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t0So4QvATZMA"
   },
   "source": [
    "# **iMaterialist Challenge (Furniture) at FGVC5**\n",
    "## **TFNW Kaggle Team**\n",
    "\n",
    "### **Get Started**\n",
    "\n",
    "To get started, you will:\n",
    "\n",
    "\n",
    "\n",
    "1.   Join the Completion\n",
    "2.   Create a Kaggle API key\n",
    "3.   Install the Kaggle Python module\n",
    "4.   Download the dataset for the competition\n",
    "\n",
    "**Join The Completion**\n",
    "\n",
    "Goto Kaggle.com and login.\n",
    "\n",
    "Once logged in, goto the competition page and select the JOIN COMPETITION button\n",
    "\n",
    "https://www.kaggle.com/c/imaterialist-challenge-furniture-2018\n",
    "\n",
    "**Create Kaggle API Key**\n",
    "\n",
    "To download this dataset you will use the Kaggle API for downloading datasets. To use the API, you must first create a Kaggle API Key. To create your API Key, do:\n",
    "\n",
    "\n",
    "\n",
    "1.   Click on your Profile\n",
    "2.   Select My Accont\n",
    "3.   Under API, Select Create New API Token\n",
    "4.   Download the API Key (kaggle.json)\n",
    "5.   Copy the API key to:  ~/.kaggle/kaggle.json\n",
    "6.   On Windows, that would be: \\Users\\<username>\\.kaggle\\kaggle.json\n",
    "\n",
    "**Install the Kaggle Python Module**\n",
    "\n",
    "C:> pip install kaggle\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in c:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\n",
      "Requirement already satisfied: kaggle in c:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages (from kaggle)\n",
      "Requirement already satisfied: urllib3>=1.15 in c:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages (from kaggle)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages (from kaggle)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages (from kaggle)\n"
     ]
    }
   ],
   "source": [
    "# Get the latest version of pip\n",
    "!python -m pip install --upgrade pip\n",
    "\n",
    "# Install the Kaggle module\n",
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O_qwEEOlZEKi"
   },
   "source": [
    "\n",
    "\n",
    "### Download the Dataset Dictionary\n",
    "\n",
    "The dataset consists of a dataset dictionary and the data. The dataset dictionary is a JSON file that contains the URL location and label for each image in the dataset. We need to download this first using the Kaggle python module:\n",
    "\n",
    "C:> kaggle competitions download -c imaterialist-challenge-furniture-2018\n",
    "\n",
    "This will place the data under:\n",
    "\n",
    "Linux/Mac: ~/.Kaggle/competitions/imaterialist-challenge-furniture-2018<br/>\n",
    "Windows: \\Users\\<username>\\.Kaggle\\competitions\\imaterialist-challenge-furniture-2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.json: Skipping, found more recently modified local copy (use --force to force download)\n",
      "validation.json: Skipping, found more recently modified local copy (use --force to force download)\n",
      "test.json: Skipping, found more recently modified local copy (use --force to force download)\n",
      "sample_submission_randomlabel.csv: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c imaterialist-challenge-furniture-2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will install and import some libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\n",
      "Requirement already satisfied: h5py in c:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages (from h5py)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages (from h5py)\n",
      "Requirement already satisfied: pillow in c:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages (from requests)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages (from requests)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages (from requests)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages (from requests)\n"
     ]
    }
   ],
   "source": [
    "# numpy for the high performance in-memory matrix/array storage and operations.\n",
    "!pip install numpy   \n",
    "# h5py for the HD5 filesystem high performance file storage of big data.\n",
    "!pip install h5py   \n",
    "# Python image manipulation library (replaces PIL)\n",
    "!pip install pillow  \n",
    "# requests for HTTP operations\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Import numpy for the high performance in-memory matrix/array storage and operations.\n",
    "import numpy as np\n",
    "\n",
    "# Import h5py for the HD5 filesystem high performance file storage of big data.\n",
    "import h5py\n",
    "\n",
    "# Import PIL.Image for Python image manipulation library. \n",
    "from PIL import Image\n",
    "\n",
    "# Import json and requests for HTTP operations\n",
    "import json, requests\n",
    "\n",
    "# Import the Byte and String IO library for extracing data returned (response) frome HTTP requests.\n",
    "from io import BytesIO, StringIO\n",
    "\n",
    "# Import time to record timing\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RUaKvpVUbxIm"
   },
   "source": [
    "# **Loading the Dataset (ETL)**\n",
    "\n",
    "## ** Overview **\n",
    "\n",
    "The loading and storing of the image data and corresponding data is done in several steps. To facilate minimizing the loading time and memory requirements, the process is broken into batches, and loaded and stored in concurrent (parallel) groups. \n",
    "\n",
    "Both the size of batches and the number of concurrent load/stores of batches is configurable. The overall process is as follows:\n",
    "\n",
    "1. Load the Dataset Dictionary (described below) for the training (or test or validation) data.\n",
    "2. Determine the number of images to load/store from the data dictionary.\n",
    "3. Split the loading/storing of images into batches, based on batch size.\n",
    "4. Sequentially load groups of batches, but where each batch within the batch group is concurrently processed (loaded and stored).\n",
    "\n",
    "## ** Dispatch **\n",
    "\n",
    "The function load_dispatcher() handles the dispatching of loading/storing of batches. It starts by\n",
    "taking the location of the dataset dictionary and loads it into memory. The dataset dictionary contains the location of each image and corresponding label.\n",
    "\n",
    "The dataset dictionary is in json format, as follows, where [image] is a list of image locations and [annotations] is a list of corresponding labels.\n",
    " \n",
    " {<br/>\n",
    "\"images\" : [image],<br/>\n",
    "\"annotations\" : [annotation],<br/>\n",
    "}\n",
    "\n",
    "The dispatcher makes a HTTP request (requests.get(url)) for the dataset dictionary and extracts the dataset dictionary from the contents of the response (requests.get(url).content). The dispatcher extracts it as raw byte data (ByteIO) and loads the dataset dictionary into a json format (json.load).\n",
    " \n",
    "The dispatcher calculates the number of batches based on the number of images and the batch size. The batches are then sequenced into groups (for i in range(0, batches, concurrent)), where the size of the group is the number of concurrent threads. For each group, the dispatcher creates a thread for each batch to load/store asynchronously (i.e., job). The dispatcher waits for all the concurrent jobs to complete. Based on the time to process the batch group, the dispatcher estimates the time to load/store all the remaining batches.\n",
    "\n",
    "Note, you can set the size of the batches, the size to rescale the images to, and whether to convert to grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library for thread execution\n",
    "import threading\n",
    "\n",
    "def load_dispatcher(url, batch_type, batch_size=200, size=(300,300), grayscale=False, concurrent=5):\n",
    "    \"\"\" Load the Data in Batches \n",
    "    url - location of data dictionary\n",
    "    batch_type - training, validation or test\n",
    "    batch_size - size of the batch\n",
    "    size - size to rescale image to\n",
    "    grayscale - flag to convert image to grayscale\n",
    "    concurrent - the number of concurrent (parallel)) batch loads\n",
    "    \"\"\"\n",
    "    \n",
    "    # First retreive the dataset dictionary, which is in a JSON format. \n",
    "    # Dictionary is stored remote: We will make a HTTP request\n",
    "    if url.startswith(\"http\"):\n",
    "        datadict = json.load( requests.get(url).content )\n",
    "    # Dictionary is stored locally\n",
    "    else:\n",
    "        datadict = json.load( open( url ) )\n",
    "   \n",
    "    # The number of batches\n",
    "    batches = int(len(datadict['images']) / batch_size)\n",
    "    \n",
    "    # Sequentially Load each batch group (i.e., concurrent)\n",
    "    for i in range(0, batches, concurrent):\n",
    "        # Start time for the batch group\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Listof threads, corresponding to to the processing of each batch in the batch group\n",
    "        threads = []\n",
    "        # Create and Start a processing thread for each batch in the batch group\n",
    "        for j in range(concurrent):\n",
    "            t = threading.Thread(target=load_and_store_batch, args=(datadict, batch_type, i + j, batch_size, size, grayscale,))\n",
    "            # Keep track (remember) of the thread\n",
    "            threads.append(t)\n",
    "            # Start the thread\n",
    "            t.start()\n",
    "        # Join the threads into a single wait for all threads to complete\n",
    "        for t in threads:\n",
    "            t.join()\n",
    "                  \n",
    "        # Calculate elapsed time in seconds to load this batch group\n",
    "        elapse = int(time.time() - start_time)\n",
    "            \n",
    "        # Estimate remaining time in minutes for loading remaining barches.\n",
    "        remaining = int( ( ( batches - i ) / concurrent ) * elapse ) / 60\n",
    "        \n",
    "        print(\"Remaining time %d mins\" % remaining)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** Load and Store the Data Batches **\n",
    "\n",
    "We have a mass amount of images: 194,828 training, 6,400 validation, 12,800 test. If we tried to load it all, we would need 54GB of memory! \n",
    "\n",
    "Instead, we will load the data into smaller training (validation and test) batches and store them separately on disk. We use the loaded data dictionary and sequentially move through it (batch_size at a time) to build the batches and save them into a HD5 high performance file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_store_batch(datadict, batch_type, pos, batch_size, size, grayscale):\n",
    "    \"\"\" Process loading (extration), handling (transformation) and storing (loading) as a batch \n",
    "    batch_type - training, validation or test\n",
    "    pos - the batch slice position in the data (i.e., the first, the second, etc)\n",
    "    batch_size - size of the batch\n",
    "    size - size to rescale image to\n",
    "    grayscale - flag to convert image to grayscale\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    start = pos * batch_size\n",
    "    images, labels = load_batch(datadict, start, batch_size, size, grayscale )\n",
    "        \n",
    "    # Calculate elapsed time in seconds to load this batch\n",
    "    elapse = int(time.time() - start_time)\n",
    "        \n",
    "    print(\"Batch Loaded %d: %d secs\" % (pos, elapse))\n",
    "        \n",
    "    # Write the batch to disk as HD5 file\n",
    "    with h5py.File('contents\\\\' + batch_type + '\\\\images' + str(pos) + '.h5', 'w') as hf:\n",
    "        hf.create_dataset(\"images\",  data=images)\n",
    "    #with h5py.File('contents\\\\' + batch_type + '\\\\labels' + str(pos) +  '.h5', 'w') as hf:\n",
    "        hf.create_dataset(\"labels\",  data=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** Extraction / Dataset Directory **\n",
    "\n",
    "The load_batch() function uses the location of each image specified in the slice of the dataset dictionary to load the images into memory, do transformations and store the images on disk, as a batch. The slice is defined by a start position in the dataset dictionary and length, denoted by batch_size.\n",
    "\n",
    "## **Transform / Load**\n",
    " \n",
    "The images are a mix of grayscale, RGB and RGBA (alpha channel) images, and are of different pixel sizes. For the neural network, they all need to be the same size. We will rescale each of our images to be 300 by 300 pixels (default), but you can choose another scale with the size parameter. THe image data will then be packed into a high performance numpy 3D matrix. The row/column are the height and width (300,300) and the third dimension are the channels (3). For the grayscale and RGBA images, we convert them to RGB.\n",
    "\n",
    "The images will be stored in the list images[] and the corresponding labels in the list labels[].\n",
    "\n",
    "The load_batch() function loads a batch of images from the training, validation or test data and does the transform function. The images and corresponding labels are then returned as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "n_j3e0kiZELK"
   },
   "outputs": [],
   "source": [
    "timeout = 6   # timeout (seconds) for reading the image from the web\n",
    "retries = 2   # Number of times to retry reading the image over the network\n",
    "\n",
    "def load_batch(datadict, start, batch_size=200, size=(300,300), grayscale=False ):\n",
    "    \"\"\" Load the training dataset \n",
    "    datadict - data image/label dictionary\n",
    "    start - index to start reading batch of images\n",
    "    batch_size - number of images to read (None = all images)\n",
    "    grayscale - flag if image should be converted to grayscale\n",
    "    \"\"\"\n",
    "    \n",
    "    images = [] # List containing the images\n",
    "    labels = [] # List containing the corresponding labels for the images\n",
    "    \n",
    "    # Number of images to load\n",
    "    if batch_size == None:\n",
    "        batch_size = len(datadict['images'])\n",
    "      \n",
    "    # Final shape of image Height, Width\n",
    "    if grayscale == True:\n",
    "        shape = size\n",
    "    # Final shape of image Height, Width, Channels(3)\n",
    "    else:\n",
    "        shape = size + (3,)\n",
    "        \n",
    "    not_loaded = 0 # Number of images that failed to load in the batch\n",
    "            \n",
    "    # Load the batch of images/labels from the Data Dictionary\n",
    "    end = start + batch_size\n",
    "    for i in range(start, end): \n",
    "        image_url = datadict['images'][i]['url'][0]\n",
    "        label_id  = datadict['annotations'][i]['label_id']\n",
    "\n",
    "        # Keep trying to read the image over the network on failure upto retries number of times\n",
    "        for retry in range(retries):\n",
    "            # Download, resize and convert images to arrays\n",
    "            try:\n",
    "                # Make HTTP request fot the image data\n",
    "                response = requests.get(image_url, timeout=10)\n",
    "\n",
    "                # Use the PIL.Image libary to load the image data as au uncompressed RGB or Grayscale bitmap\n",
    "                if grayscale == True:\n",
    "                    pixels = Image.open(BytesIO(response.content)).convert('LA')\n",
    "                else:\n",
    "                    pixels = Image.open(BytesIO(response.content))\n",
    "\n",
    "                # Resize the image to be all the same size\n",
    "                pixels = pixels.resize(size, resample=Image.LANCZOS)\n",
    "\n",
    "                # Load the image into a 3D numpy array\n",
    "                image = np.asarray(pixels)\n",
    "\n",
    "                # Discard image if it does not fit the final shape\n",
    "                if image.shape != shape:\n",
    "                    if grayscale == False:\n",
    "                        # Was a gray scale image\n",
    "                        if image.shape == size:\n",
    "                            # Extend to three channels, replicating the single channel\n",
    "                            pixels = pixels.convert('RGB')\n",
    "                            image = np.asarray(pixels)\n",
    "                            break\n",
    "                        # Is RGBA image (4 channels)\n",
    "                        if image.shape == size + (4,):\n",
    "                            # Remove Alpha Channel from Image\n",
    "                            pixels = pixels.convert('RGB')\n",
    "                            image = np.asarray(pixels)\n",
    "                            break\n",
    "                            \n",
    "                    # Unrecognized shape\n",
    "                    not_loaded += 1\n",
    "                    retry = retries\n",
    "                    break\n",
    "            except Exception as ex:\n",
    "                if retry < retries-1:\n",
    "                    continue\n",
    "                #print(\"CAN'T FETCH IMAGE\", image_url)\n",
    "                retry = retries\n",
    "            # Image was read or failed retries number of times\n",
    "            break\n",
    "                \n",
    "        if retry == retries:\n",
    "            not_loaded += 1\n",
    "            continue\n",
    "\n",
    "        # if bad image, skip\n",
    "        if np.any(image == None):\n",
    "            continue\n",
    "        # add image to images list\n",
    "        images.append( image )\n",
    "        # add corresponding label to labels list\n",
    "        labels.append( label_id )\n",
    "        \n",
    "        if (i+1) % 50 == 0:\n",
    "            print('%d Images added, %d not loaded' % ((i + 1), not_loaded))\n",
    "\n",
    "    return images, labels\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the Load\n",
    "\n",
    "The URLs below are for more laptop. You will need to modify it to the location on your laptop.\n",
    "\n",
    "Running as 5 concurrent processes in batches of 200, takes 1/2 day on my laptop with my local Internet service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KqrObUaMZELc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file contents already exists.\n",
      "A subdirectory or file contents\\\\train already exists.\n",
      "A subdirectory or file contents\\\\validation already exists.\n",
      "A subdirectory or file contents\\\\test already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 Images added, 1 not loaded\n",
      "450 Images added, 1 not loaded\n",
      "850 Images added, 1 not loaded\n",
      "650 Images added, 2 not loaded\n",
      "250 Images added, 2 not loaded\n",
      "100 Images added, 2 not loaded\n",
      "700 Images added, 3 not loaded\n",
      "500 Images added, 2 not loaded\n",
      "300 Images added, 3 not loaded\n",
      "150 Images added, 2 not loaded\n",
      "550 Images added, 2 not loaded\n",
      "900 Images added, 4 not loaded\n",
      "950 Images added, 4 not loaded\n",
      "750 Images added, 4 not loaded\n",
      "200 Images added, 2 not loaded\n",
      "Batch Loaded 0: 220 secs\n",
      "350 Images added, 5 not loaded\n",
      "600 Images added, 4 not loaded\n",
      "Batch Loaded 2: 253 secs\n",
      "800 Images added, 7 not loaded\n",
      "Batch Loaded 3: 342 secs\n",
      "1000 Images added, 6 not loaded\n",
      "Batch Loaded 4: 350 secs\n",
      "400 Images added, 8 not loaded\n",
      "Batch Loaded 1: 374 secs\n",
      "Remaining time 1214 mins\n",
      "1050 Images added, 2 not loaded\n",
      "1650 Images added, 3 not loaded\n",
      "1250 Images added, 1 not loaded\n"
     ]
    }
   ],
   "source": [
    "# Create Directories for the HD5 encoded batches\n",
    "!mkdir contents\n",
    "!mkdir contents\\\\train\n",
    "!mkdir contents\\\\validation\n",
    "!mkdir contents\\\\test\n",
    "\n",
    "# Data dictionaries\n",
    "train_url      = 'C:\\\\Users\\\\User\\\\.kaggle\\\\competitions\\\\imaterialist-challenge-furniture-2018\\\\train.json'\n",
    "test_url       = 'C:\\\\Users\\\\User\\\\.kaggle\\\\competitions\\\\imaterialist-challenge-furniture-2018\\\\test.json'\n",
    "validation_url = 'C:\\\\Users\\\\User\\\\.kaggle\\\\competitions\\\\imaterialist-challenge-furniture-2018\\\\validation.json'\n",
    "\n",
    "# Load the Training Batches\n",
    "load_dispatcher(train_url, \"train\")\n",
    "\n",
    "# Load the Validation Batches\n",
    "load_dispatcher(validation_url, \"validation\")\n",
    "\n",
    "# Load the Test Batches\n",
    "load_dispatcher(test_url, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "iMaterialist-download-dataset.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
