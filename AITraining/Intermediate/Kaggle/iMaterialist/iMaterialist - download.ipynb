{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t0So4QvATZMA"
   },
   "source": [
    "# **iMaterialist Challenge (Furniture) at FGVC5**\n",
    "## **TFNW Kaggle Team**\n",
    "\n",
    "### **Get Started**\n",
    "\n",
    "To get started, you will:\n",
    "\n",
    "\n",
    "\n",
    "1.   Join the Completion\n",
    "2.   Create a Kaggle API key\n",
    "3.   Install the Kaggle Python module\n",
    "4.   Download the dataset for the competition\n",
    "\n",
    "**Join The Completion**\n",
    "\n",
    "Goto Kaggle.com and login.\n",
    "\n",
    "Once logged in, goto the competition page and select the JOIN COMPETITION button\n",
    "\n",
    "https://www.kaggle.com/c/imaterialist-challenge-furniture-2018\n",
    "\n",
    "**Create Kaggle API Key**\n",
    "\n",
    "To download this dataset you will use the Kaggle API for downloading datasets. To use the API, you must first create a Kaggle API Key. To create your API Key, do:\n",
    "\n",
    "\n",
    "\n",
    "1.   Click on your Profile\n",
    "2.   Select My Accont\n",
    "3.   Under API, Select Create New API Token\n",
    "4.   Download the API Key (kaggle.json)\n",
    "5.   Copy the API key to:  ~/.kaggle/kaggle.json\n",
    "6.   On Windows, that would be: \\Users\\<username>\\.kaggle\\kaggle.json\n",
    "\n",
    "**Install the Kaggle Python Module**\n",
    "\n",
    "C:> pip install kaggle\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the latest version of pip\n",
    "!python -m pip install --upgrade pip\n",
    "\n",
    "# Install the Kaggle module\n",
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O_qwEEOlZEKi"
   },
   "source": [
    "\n",
    "\n",
    "### Download the Dataset Dictionary\n",
    "\n",
    "The dataset consists of a dataset dictionary and the data. The dataset dictionary is a JSON file that contains the URL location and label for each image in the dataset. We need to download this first using the Kaggle python module:\n",
    "\n",
    "C:> kaggle competitions download -c imaterialist-challenge-furniture-2018\n",
    "\n",
    "This will place the data under:\n",
    "\n",
    "Linux/Mac: ~/.Kaggle/competitions/imaterialist-challenge-furniture-2018<br/>\n",
    "Windows: \\Users\\<username>\\.Kaggle\\competitions\\imaterialist-challenge-furniture-2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c imaterialist-challenge-furniture-2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will install and import some libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy for the high performance in-memory matrix/array storage and operations.\n",
    "!pip install numpy   \n",
    "# h5py for the HD5 filesystem high performance file storage of big data.\n",
    "!pip install h5py   \n",
    "# Python image manipulation library (replaces PIL)\n",
    "!pip install pillow  \n",
    "# requests for HTTP operations\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy for the high performance in-memory matrix/array storage and operations.\n",
    "import numpy as np\n",
    "\n",
    "# Import h5py for the HD5 filesystem high performance file storage of big data.\n",
    "import h5py\n",
    "\n",
    "# Import PIL.Image for Python image manipulation library. \n",
    "from PIL import Image\n",
    "\n",
    "# Import json and requests for HTTP operations\n",
    "import json, requests\n",
    "\n",
    "# Import the Byte and String IO library for extracing data returned (response) frome HTTP requests.\n",
    "from io import BytesIO, StringIO\n",
    "\n",
    "# Import time to record timing\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RUaKvpVUbxIm"
   },
   "source": [
    "# **Loading the Dataset (ETL)**\n",
    "\n",
    "** Extraction / Dataset Directory **\n",
    "\n",
    "The load_batches() function takes the location of the dataset dictionary and loads it into memory. The function in conjunction with load_batch() uses the location of each image specified in the dictionary to load the images into memory in batches, do transformations and store the batches on disk.\n",
    "\n",
    "The dataset dictionary is in json format, as follows, where [image] is a list of image locations and [annotations] is a list of corresponding labels.\n",
    " \n",
    " {<br/>\n",
    "\"images\" : [image],<br/>\n",
    "\"annotations\" : [annotation],<br/>\n",
    "}\n",
    " \n",
    "The load_batches() function makes a HTTP request (requests.get(url)) for the dataset dictionary and extracts the dataset dictionary from the contents of the response (requests.get(url).content). The function extracts it as raw byte data (ByteIO) and loads the dataset dictionary into a json format (json.load).\n",
    "\n",
    "THe load_batches() function then splits the image and corresponding label extraction into batches, where the size of each batch is specified by the batch_size parameter.\n",
    "\n",
    "**Transform / Load**\n",
    " \n",
    "The images are all RGB images, but are of different pixel sizes. For the neural network, they all need to be the same size. We will rescale each of our images to be 300 by 300 pixels (default), but you can choose another scale with the size parameter. THe image data will then be packed into a high performance numpy 3D matrix. The row/column are the height and width (300,300) and the third dimension are the channels (3).\n",
    "\n",
    "The images will be stored in the list images[] and the corresponding labels in the list labels[].\n",
    "\n",
    "The load_batch() function loads a batch of images from the training, validation or test data and does the transform function. The images and corresponding labels are then returned as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "n_j3e0kiZELK"
   },
   "outputs": [],
   "source": [
    "def load_batch(datadict, start, batch_size=200, size=(300,300), grayscale=False ):\n",
    "    \"\"\" Load the training dataset \n",
    "    datadict - data image/label dictionary\n",
    "    start - index to start reading batch of images\n",
    "    batch_size - number of images to read (None = all images)\n",
    "    grayscale - flag if image should be converted to grayscale\n",
    "    \"\"\"\n",
    "    \n",
    "    images = [] # List containing the images\n",
    "    labels = [] # List containing the corresponding labels for the images\n",
    "    \n",
    "    # Number of images to load\n",
    "    if batch_size == None:\n",
    "        batch_size = len(datadict['images'])\n",
    "      \n",
    "    # Final shape of image Height, Width\n",
    "    if grayscale == True:\n",
    "        shape = size\n",
    "    # Final shape of image Height, Width, Channels(3)\n",
    "    else:\n",
    "        shape = size + (3,)\n",
    "            \n",
    "    # Load the batch of images/labels from the Data Dictionary\n",
    "    end = start + batch_size\n",
    "    for i in range(start, end): \n",
    "        image_url = datadict['images'][i]['url'][0]\n",
    "        label_id  = datadict['annotations'][i]['label_id']\n",
    "        \n",
    "        not_loaded = 0\n",
    "\n",
    "        # Download, resize and convert images to arrays\n",
    "        try:\n",
    "            # Make HTTP request fot the image data\n",
    "            response = requests.get(image_url, timeout=5)\n",
    "            \n",
    "            # Use the PIL.Image libary to load the image data as au uncompressed RGB or Grayscale bitmap\n",
    "            if grayscale == True:\n",
    "                image = Image.open(BytesIO(response.content)).convert('LA')\n",
    "            else:\n",
    "                image = Image.open(BytesIO(response.content))\n",
    "            \n",
    "            # Resize the image to be all the same size\n",
    "            image = image.resize(size, resample=Image.LANCZOS)\n",
    "            \n",
    "            # Load the image into a 3D numpy array\n",
    "            image = np.asarray(image)\n",
    "            \n",
    "            # Discard image if it does not fit the final shape\n",
    "            assert image.shape == shape\n",
    "        except Exception as ex:\n",
    "            not_loaded += 1\n",
    "            continue\n",
    "        \n",
    "        # if bad image, skip\n",
    "        if np.any(image == None):\n",
    "            continue\n",
    "        # add image to images list\n",
    "        images.append( image )\n",
    "        # add corresponding label to labels list\n",
    "        labels.append( label_id )\n",
    "        \n",
    "        if (i+1) % 50 == 0:\n",
    "            print('%d Images added, %d not loaded' % ((i - start + 1), not_loaded))\n",
    "\n",
    "    return images, labels\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CohKeVWbZELY"
   },
   "source": [
    "### Load and Store the Data Batches\n",
    "\n",
    "We have a mass amount of images: 194,828 training, 6,400 validation, 12,800 test. If we tried to load it all, we would need 54GB of memory! \n",
    "\n",
    "Instead, we will load the data into smaller training batches and store them separately on disk. We use the loaded data dictionary and sequentially move through it (batch_size at a time) to build the batches and save them into a HD5 high performance file system.\n",
    "\n",
    "Note, you can set the size of the batches, the size to rescale the images to, and whether to convert to grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batches(url, batch_type, batch_size=200, size=(300,300), grayscale=False):\n",
    "    \"\"\" Load the Data in Batches \n",
    "    url - location of data dictionary\n",
    "    batch_type - training, validation or test\n",
    "    batch_size - size of the batch\n",
    "    size - size to rescale image to\n",
    "    grayscale - flag to convert image to grayscale\n",
    "    \"\"\"\n",
    "    \n",
    "    # First retreive the dataset dictionary, which is in a JSON format. \n",
    "    # Dictionary is stored remote: We will make a HTTP request\n",
    "    if url.startswith(\"http\"):\n",
    "        datadict = json.load( requests.get(url).content )\n",
    "    # Dictionary is stored locally\n",
    "    else:\n",
    "        datadict = json.load( open( url ) )\n",
    "   \n",
    "    # The number of batches\n",
    "    batches = int(len(datadict['images']) / batch_size)\n",
    "    \n",
    "    # Sequentially Load each batch\n",
    "    for i in range(batches):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        start = i * batch_size\n",
    "        images, labels = load_batch(datadict, start, batch_size, size, grayscale )\n",
    "        \n",
    "        # Calculate elapsed time in seconds to load this batch\n",
    "        elapse = int(time.time() - start_time)\n",
    "        # Estimate remaining time in minutes for loading remaining barches.\n",
    "        remaining = int( (batches - i) * elapse ) / 60\n",
    "        \n",
    "        print(\"Batch Loaded %d: %d secs, remaining %d mins\" % (i, elapse, remaining))\n",
    "        \n",
    "        # Write the batch to disk as HD5 file\n",
    "        with h5py.File('contents\\\\' + batch_type + '\\\\images' + str(i) + '.h5', 'w') as hf:\n",
    "            hf.create_dataset(\"images\",  data=images)\n",
    "        with h5py.File('contents\\\\' + batch_type + '\\\\labels' + str(i) +  '.h5', 'w') as hf:\n",
    "            hf.create_dataset(\"labels\",  data=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The URL below is for more laptop. You will need to modify it to the location on your laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KqrObUaMZELc"
   },
   "outputs": [],
   "source": [
    "# Create Directories for the HD5 encoded batches\n",
    "!mkdir contents\n",
    "!mkdir contents\\\\train\n",
    "!mkdir contents\\\\validation\n",
    "!mkdir contents\\\\test\n",
    "\n",
    "# Data dictionaries\n",
    "train_url      = 'C:\\\\Users\\\\User\\\\.kaggle\\\\competitions\\\\imaterialist-challenge-furniture-2018\\\\train.json'\n",
    "test_url       = 'C:\\\\Users\\\\User\\\\.kaggle\\\\competitions\\\\imaterialist-challenge-furniture-2018\\\\test.json'\n",
    "validation_url = 'C:\\\\Users\\\\User\\\\.kaggle\\\\competitions\\\\imaterialist-challenge-furniture-2018\\\\validation.json'\n",
    "\n",
    "# Load the Training Batches\n",
    "load_batches(train_url, \"train\")\n",
    "\n",
    "# Load the Validation Batches\n",
    "load_batches(validation_url, \"validation\")\n",
    "\n",
    "# Load the Test Batches\n",
    "load_batches(test_url, \"test\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "iMaterialist-download-dataset.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
