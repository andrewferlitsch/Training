{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gap Data Engineering Framework - CV Code Along with TensorFlow\n",
    "\n",
    "## Sign-Language Dataset\n",
    "\n",
    "We will do the following in this tutorial:\n",
    "\n",
    "    1. Install the VISION module of the Gap Framework.\n",
    "    2. Install TensorFlow for Machine Learning Model.\n",
    "    3. Use the VISION module to preprocess the image data and make min-batches for training.\n",
    "    4. Train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Vision Module\n",
    "\n",
    "We start by importing the Gap Vision module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Gap Vision module\n",
    "from vision import Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install TensorFlow\n",
    "\n",
    "Next we import the TensorFlow package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "# import Tensorflow\n",
    "# Importing Tensorflow\n",
    "import tensorflow as tf\n",
    "print( tf.__version__ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Source\n",
    "\n",
    "Github Public Repository - https://github.com/EvilPort2/Sign-Language\n",
    "\n",
    "<i>\"The first thing I did was, I created 10 gesture samples using OpenCV. For each gesture I captured 1200 images which were 50x50 pixels. All theses images were in grayscale which is stored in the gestures/ folder. The gestures/0/ folder contains 1200 blank images which signify \"none\" gesture. Also I realised that keeping this category increased my model's accuracy to 99% from a laughable 82%.\"</i>\n",
    "\n",
    "Let's go to the downloaded images and see what's there. Let's first check that we are in the correct directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"C:\\\\Users\\\\'\\\\Desktop\\\\Training\\\\AITraining\\\\Intermediate\\\\Machine Learning\\\\sign-lang\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see under the gestures directory, we have folders 0 through 26. Folder 0 is the none image, while folders 1 through 26 have images for the letters A..Z, respectively.\n",
    "\n",
    "Let's look under one of the folders (i.e., folder 1 for the letter A):\n",
    "\n",
    "<img src='gestures.jpg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Images Collections\n",
    "\n",
    "We will use the Images class to create a collection for each set (i.e., letter in alphabet) of training images.\n",
    "\n",
    "To load and process the images, we do:\n",
    "    1. Each subfolder under gestures corresponds to a letter, where the subfolder name is the label.\n",
    "    2. Get a list of all files (images) under each subfolder.\n",
    "    3. Create an Images collection per subfolder, where the files in the subfolder are the images, and the subfolder name is the label.\n",
    "\n",
    "For the config(uration) options:\n",
    "    - Process as grayscale images\n",
    "    - To reduce storage space, we are not going to store the raw pixel data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7.052011013031006\n",
      "1 7.190010070800781\n",
      "10 8.081011533737183\n",
      "11 7.5000104904174805\n",
      "12 7.570010423660278\n",
      "13 7.662010908126831\n",
      "14 12.601017713546753\n",
      "15 6.170008659362793\n",
      "16 7.514014720916748\n",
      "17 5.990008354187012\n",
      "18 5.862013339996338\n",
      "19 6.27000880241394\n",
      "2 9.427016258239746\n",
      "20 5.75000786781311\n",
      "21 6.360008955001831\n",
      "22 5.7120091915130615\n",
      "23 6.340008735656738\n",
      "24 4.982008218765259\n",
      "25 5.334014892578125\n",
      "26 6.292011260986328\n",
      "3 5.78000807762146\n",
      "4 6.112008571624756\n",
      "5 4.940006971359253\n",
      "6 5.462008953094482\n",
      "7 4.792011976242065\n",
      "8 4.700006723403931\n",
      "9 4.620006561279297\n",
      "Total Time: 176.0652792453766\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# A list of the Images object for each subfolder (i.e.,letter)\n",
    "collections = []\n",
    "\n",
    "total_time = 0\n",
    "\n",
    "# There are 27 sets of images under gestures, each in its own subfolder\n",
    "for label in os.listdir(\"gestures\"):\n",
    "    subfolder = \"gestures/\" + label + \"/\"\n",
    "    \n",
    "    # Let's get the list of images under the subfolder for this set.\n",
    "    files = os.listdir(subfolder)\n",
    "    \n",
    "    # We need the relative path to each file, we will use a generator for this purpose\n",
    "    files = [subfolder + file for file in files]\n",
    "    \n",
    "    # Let's create now the Images object for the subfolder of images\n",
    "    images = Images(files, labels=int(label), name='tmp' + label, config=['grayscale', 'flatten', 'nostore'])\n",
    "    \n",
    "    collections.append(images)\n",
    "    \n",
    "    # time metrics\n",
    "    print(label, images.time)\n",
    "    total_time += images.time\n",
    "\n",
    "print(\"Total Time:\", total_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into Training and Test\n",
    "\n",
    "Gap v0.9 (alpha) doesn't have a Dataset class yet for Images, so we are going to prepare our training data with a little brute force. Don't worry, that will change soon.\n",
    "\n",
    "    - We use the split property to split each collection into training and test data\n",
    "    - We use the list extend() method to build our list w/o copying any data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will collect all the training sets from each collection into a list\n",
    "X_train = []\n",
    "X_test  = []\n",
    "Y_train = []\n",
    "Y_test  = []\n",
    "\n",
    "# 80% of the images will be used for training (note that the list is randomized)\n",
    "for images in collections:\n",
    "    images.split = 0.2, 42\n",
    "\n",
    "    # When used as a getter, the split property will return the training / test data and labels the same as the sci-learn\n",
    "    # procedure train_test_split()\n",
    "    x_train, x_test, y_train, y_test = images.split\n",
    "    \n",
    "    # Let's concatenate (without copying) the split of each collection to a single contiguous list\n",
    "    X_train.extend(x_train)\n",
    "    X_test.extend(x_test)\n",
    "    Y_train.extend(y_train)\n",
    "    Y_test.extend(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some more brute force correction. We will change the python list for the collections to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train = np.asarray(X_train)\n",
    "Y_train = np.asarray(Y_train)\n",
    "X_test = np.asarray(X_test)\n",
    "Y_test = np.asarray(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last step, for this Tensorflow model, we need to convert our labels into a one hot encoding (dummy variable conversion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25920, 27)\n"
     ]
    }
   ],
   "source": [
    "def convert_labels_to_one_hot_encoding(Y, C):\n",
    "    \"\"\" This function will do the reshape and conversion (from Coursera)\"\"\"\n",
    "    Y = np.eye(C)[Y.reshape(-1)]\n",
    "    return Y\n",
    "\n",
    "# Let's do the conversion\n",
    "Y_train = convert_labels_to_one_hot_encoding(Y_train, 27)\n",
    "Y_test  = convert_labels_to_one_hot_encoding(Y_test, 27)\n",
    "\n",
    "# Let's print the shape of our labels\n",
    "print( Y_train.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first reset our graph, so our neural network components are all declared within the same graph\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[2500, None])\n",
    "Y = tf.placeholder(tf.float32, shape=[27, None])\n",
    "D = tf.placeholder(tf.float32, [])\n",
    "L = tf.placeholder(tf.float32, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Layer\n",
    "\n",
    "Let's now design our input layer. We need two things: weights and biases.\n",
    "\n",
    "Each input feature (pixel) will need a weight (which our model will learning during training). The weight is multipled against the value of the input (pixel), which we symbolically represent as Wx.\n",
    "\n",
    "Each output from the layer will need a bias (which our model will learning during training). The bias is added to the result of the weight multipled by the pixel value (Wx).\n",
    "\n",
    "Let's create two Tensorflow variables for our weights and biases. The weights (which we call W) will need to be a 2D matrix. The rows are the number of inputs, which is 2500 and the columns the number of outputs to the hidden layer, which will be 64.\n",
    "\n",
    "The bias will be a vector of size 64 (one for each output).\n",
    "\n",
    "We need to initialize our weights and biases to some initial value. We will initialize the weights using a random value initializer (Xavier) and initialize the biases to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(1)   # Set the same seed to get the same initialization as in this demo.\n",
    "\n",
    "# The weights for the input layer\n",
    "W1 = tf.get_variable(\"W1\", [64, 2500], initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "\n",
    "# The bias for the output from the input layer\n",
    "b1 = tf.get_variable(\"b1\", [64, 1], initializer=tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first layer (input layer)\n",
    "Z1 = tf.add(tf.matmul(W1, X), b1)\n",
    "\n",
    "# Let's add the activation function to the output signal from the first layer\n",
    "A1 = tf.nn.relu(Z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Hidden Layer\n",
    "\n",
    "The first hidden layer will have 64 inputs (outputs from input layer) and 32 outputs. Each input will need a weight and each output a bias (which we will train). Each output will be passed through the linear rectifier unit (RELU) activation function.\n",
    "\n",
    "We will initialize the weights using a random value initializer (Xavier) and initialize the biases to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = tf.get_variable(\"W2\", [32, 64], initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "b2 = tf.get_variable(\"b2\", [32, 1], initializer=tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct the first hidden layer\n",
    "\n",
    "    Create a node that will multiply the weights (W2) against the outputs of the input layer (A1).\n",
    "    Create a node that adds the bias to the above node (W2 * A1)\n",
    "    Pass the outputs from the (first) hidden layer through a dropout layer\n",
    "    Pass the outputs from the dropout layer through a RELU activation function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second layer (first hidden layer)\n",
    "Z2 = tf.add(tf.matmul(W2, A1), b2) \n",
    "\n",
    "# Let's add the dropout layer to the output signal from the second layer\n",
    "D2 = tf.nn.dropout(Z2, keep_prob=D)\n",
    "\n",
    "# Let's add the activation function to the output signal from the dropout layer\n",
    "A2 = tf.nn.relu(D2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Hidden Layer\n",
    "\n",
    "The second hidden layer will have 32 inputs (outputs from first hidden layer) and 20 outputs. Each input will need a weight and each output a bias (which we will train). Each output will be passed through the linear rectifier unit (RELU) activation function.\n",
    "\n",
    "We will initialize the weights using a random value initializer (Xavier) and initialize the biases to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "W3 = tf.get_variable(\"W3\", [20, 32], initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "b3 = tf.get_variable(\"b3\", [20, 1], initializer=tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct the second hidden layer.\n",
    "\n",
    "    Create a node that will multiply the weights (W3) against the outputs of the first hidden layer (A2).\n",
    "    Create a node that adds the bias to the above node (W3 * A2)\n",
    "    Pass the outputs from the second hidden layer through a RELU activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The third layer (second hidden layer)\n",
    "Z3 = tf.add(tf.matmul(W3, A2), b3) \n",
    "\n",
    "# Let's add the activation function to the output signal from the third layer\n",
    "A3 = tf.nn.relu(Z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "\n",
    "The output layer will have 20 inputs (outputs from the second hidden layer) and 27 outputs (one for each letter and None). Each input will need a weight and each output a bias (which we will train). The 27 outputs will be passed through a softmax activation function.\n",
    "\n",
    "We will initialize the weights using a random value initializer (Xavier) and initialize the biases to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "W4 = tf.get_variable(\"W4\", [27, 20], initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "b4 = tf.get_variable(\"b4\", [27, 1], initializer=tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct the output layer.\n",
    "\n",
    "    Create a node that will multiply the weights (W4) against the outputs of the second hidden layer (A3).\n",
    "    Create a node that adds the bias to the above node (W4 * A3)\n",
    "    Pass the outputs from the output layer through a SOFTMAX squashing function (done by the optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fourth layer (output layer)\n",
    "Z4 = tf.add(tf.matmul(W4, A3), b4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "\n",
    "Now its time to design our optimizer. Let's start by designing our cost function. We will use the mean value of the softmax cross entropy between the predicted labels and actual labels. This is what we want to reduce on each batch (aka the cost)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=tf.transpose(Z4), labels=tf.transpose(Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's design our optimizer. This is the method that adjusts the values of the weights and biases, based on minizing the cost value during training.\n",
    "\n",
    "We also need to set a learning rate. This is multiplied against the gradient calculation. It's used to prevent huge swings in setting weights which can result in either converging at a local (instead of global) optima, or not converging at all (infinite gradient). We will set the learning rate when we run the graph using the placeholder L.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The learning rate for Gradient Descent algorithm\n",
    "optimizer = tf.train.GradientDescentOptimizer(L).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "epochs = 25                                    # run a 25 epochs\n",
    "batch_size = 100                               # for each epoch, train in batches of 100 images\n",
    "number_of_images = len(X_train)                # number of images in training data\n",
    "\n",
    "# Feed Dictionary Parameters\n",
    "keep_prob = 0.9                                # percent of outputs to keep in dropout layer\n",
    "learning_rate = 0.004                          # the learning rate for graident descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 2.6024440230089727\n",
      "Epoch:  1 1.8829405013773892\n",
      "Epoch:  2 1.3729867978330745\n",
      "Epoch:  3 1.0144998312399194\n",
      "Epoch:  4 0.8078569689600164\n",
      "Epoch:  5 0.64922806351629\n",
      "Epoch:  6 0.5507119966663679\n",
      "Epoch:  7 0.4809992052542772\n",
      "Epoch:  8 0.42571273187901754\n",
      "Epoch:  9 0.3855076012593554\n",
      "Epoch:  10 0.35134849454991834\n",
      "Epoch:  11 0.3184934920634945\n",
      "Epoch:  12 0.2944728962386667\n",
      "Epoch:  13 0.272749159747598\n",
      "Epoch:  14 0.2541119466575301\n",
      "Epoch:  15 0.2332139004697901\n",
      "Epoch:  16 0.22576703361152856\n",
      "Epoch:  17 0.20729639536510563\n",
      "Epoch:  18 0.19759646106986006\n",
      "Epoch:  19 0.18437778887529516\n",
      "Epoch:  20 0.1767506640670555\n",
      "Epoch:  21 0.16767139829026398\n",
      "Epoch:  22 0.15965445201959044\n",
      "Epoch:  23 0.1516163613499793\n",
      "Epoch:  24 0.14672508483939592\n",
      "Training Time: 110.57516121864319\n",
      "Train Accuracy: 0.73383486\n",
      "Test Accuracy: 0.7337963\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    start = time.time()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        # Initialize the variables\n",
    "        sess.run(init)\n",
    "        \n",
    "        # number of batches in an epoch\n",
    "        batches = number_of_images // batch_size\n",
    "\n",
    "        # run our training data through the neural network for each epoch\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "          epoch_cost = 0\n",
    "\n",
    "          # Run the training data through the neural network\n",
    "          for batch in range(batches):\n",
    "\n",
    "              # Calculate the start and end indices for the next batch\n",
    "              begin = (batch * batch_size)\n",
    "              end   = (batch * batch_size) + batch_size\n",
    "\n",
    "\n",
    "              # Get the next sequential batch from the training data\n",
    "              batch_xs, batch_ys = X_train[begin:end], Y_train[begin:end]\n",
    "\n",
    "              # Feed this batch through the neural network.\n",
    "              _, batch_cost = sess.run([optimizer, cost], feed_dict={X: batch_xs.T, Y: batch_ys.T, D: keep_prob, L: learning_rate})\n",
    "\n",
    "              epoch_cost += batch_cost\n",
    "\n",
    "          print(\"Epoch: \", epoch, epoch_cost / batches)\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        print(\"Training Time:\", end - start)\n",
    "\n",
    "        # Test the Model\n",
    "\n",
    "        # Let's select the highest percent from the softmax output per image as the prediction.\n",
    "        prediction = tf.equal(tf.argmax(Z4), tf.argmax(Y))\n",
    "\n",
    "        # Let's create another node for calculating the accuracy\n",
    "        accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n",
    "\n",
    "        # Now let's run our trainingt images through the model to calculate our accuracy during training\n",
    "        # Note how we set the keep percent for the dropout rate to 1.0 (no dropout) when we are evaluating the accuracy.\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train.T, Y: Y_train.T, D: 1.0}))\n",
    "\n",
    "        # Now let's run our test images through the model to calculate our accuracy on the test data\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test.T, Y: Y_test.T, D: 1.0}))\n",
    "        \n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
